{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Iris with Keras\n",
    "\n",
    "Original code by Nikolai Janakiev: \n",
    "\n",
    "https://janakiev.com/notebooks/keras-iris/\n",
    "\n",
    "This examples uses Keras and TensorFlow to classify the same Iris dataset as the previous example (where scikit learn was used).\n",
    "\n",
    "## Tasks\n",
    "\n",
    "1. Try to modify this network to behave similarly to a logistic regressor\n",
    "2. Add additional layers, and try out several activation functions, number of units per layer, etc.\n",
    "3. Try to show not only the learing curves for the validation sets, but also for the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# In order to ignore FutureWarning\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imported classes are stored as integers, but we need them in one hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "Y = enc.fit_transform(y[:, np.newaxis]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Warning:</font>** Please never forget to normalize your data, or training will be slow or even divergent.\n",
    "\n",
    "Here we normalize for mean 0 and std deviation 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Split the data set into training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.5, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Number of features and number of classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[1]\n",
    "n_classes = Y.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data set\n",
    "\n",
    "Two features on the left and the other two on the right.\n",
    "\n",
    "Please check how the feature names are also loaded above in the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "for target, target_name in enumerate(names):\n",
    "    X_plot = X[y == target]\n",
    "    plt.plot(X_plot[:, 0], X_plot[:, 1], linestyle='none', marker='o', label=target_name)\n",
    "plt.xlabel(feature_names[0])\n",
    "plt.ylabel(feature_names[1])\n",
    "plt.axis('equal')\n",
    "plt.legend();\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for target, target_name in enumerate(names):\n",
    "    X_plot = X[y == target]\n",
    "    plt.plot(X_plot[:, 2], X_plot[:, 3], linestyle='none', marker='o', label=target_name)\n",
    "plt.xlabel(feature_names[2])\n",
    "plt.ylabel(feature_names[3])\n",
    "plt.axis('equal')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the neural network\n",
    "\n",
    "The following function creates a custom model, specifying the input and output sizes (i.e. number of units), the number of nodes (or units) per hidden layer, the number of hidden layers and a name for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_model(input_dim, output_dim, nodes, num_hidden_layers=1, name='model'):\n",
    "    # Create model\n",
    "    model = Sequential(name=name)\n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add(Dense(nodes, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create several models varying the number of hidden layers, and show their structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [create_custom_model(n_features, n_classes, 8, i, 'model_{}'.format(i)) for i in range(1, 4)]\n",
    "\n",
    "for model in models:\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train all models and use TensorBoard to track the training processes\n",
    "\n",
    "Check the tensorboard results with \n",
    "\n",
    "> tensorboard --logdir logs/train/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Train all three models\n",
    "history_dict = {}\n",
    "\n",
    "## TensorBoard Callback\n",
    "cb = TensorBoard()\n",
    "\n",
    "## \n",
    "for model in models:    \n",
    "    print('Model name:', model.name)\n",
    "    history_callback = model.fit(X_train, Y_train,\n",
    "                                 batch_size=5,\n",
    "                                 epochs=50,\n",
    "                                 verbose=0,\n",
    "                                 validation_data=(X_test, Y_test),\n",
    "                                 callbacks=[cb])\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    history_dict[model.name] = [history_callback, model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot accuracy and loss from training\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(8, 6))\n",
    "\n",
    "for model_name in history_dict:\n",
    "    val_acc = history_dict[model_name][0].history['val_accuracy']\n",
    "    val_loss = history_dict[model_name][0].history['val_loss']\n",
    "    ax1.plot(val_acc, label=model_name)\n",
    "    ax2.plot(val_loss, label=model_name)\n",
    "    \n",
    "ax1.set_ylabel('validation accuracy')\n",
    "ax2.set_ylabel('validation loss')\n",
    "ax2.set_xlabel('epochs')\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
