{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Models\n",
    "\n",
    "This notebook requires the hmmlearn package, which was part of scikit-learn, but due to the fact that sequential models need different interfaces than single-sample models, at some point it was decided it should be a separate problem.\n",
    "\n",
    "Install it with \n",
    "\n",
    "> pip install hmmlearn \n",
    "\n",
    "or \n",
    "\n",
    "> conda install -c conda-forge hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install hmmlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from HMM\n",
    "\n",
    "Based on: https://hmmlearn.readthedocs.io/en/latest/auto_examples/plot_hmm_sampling.html#\n",
    "\n",
    "Example of how to sample points from Hidden Markov Models (HMM) using 3 or 4-states with a-priori known gaussian distributions for the observations.\n",
    "\n",
    "The plot shows the sequence of observations generated with the transitions between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare parameters for two models: a 4-state HMM and a 3-state HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class we used discrete observations.  Here we use as observation a sample of a gaussian distribution, whose mean and variance are associated to the particular state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducible behaviour\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "## Model 1\n",
    "\n",
    "startprob1 = np.array([0.6, 0.3, 0.1, 0.0])\n",
    "\n",
    "# The transition matrix, note that there are no transitions possible\n",
    "# between component 1 and 3\n",
    "transmat1 = np.array([[0.7, 0.2, 0.0, 0.1],\n",
    "                      [0.3, 0.5, 0.2, 0.0],\n",
    "                      [0.0, 0.3, 0.5, 0.2],\n",
    "                      [0.2, 0.0, 0.2, 0.6]])\n",
    "\n",
    "# The means of each component\n",
    "means1 = np.array([[0.0,  0.0],\n",
    "                  [0.0, 11.0],\n",
    "                  [9.0, 10.0],\n",
    "                  [11.0, -1.0]])\n",
    "# The covariance of each component\n",
    "#covars = .5 * np.tile(np.identity(2), (4, 1, 1))\n",
    "\n",
    "covars1 = np.ndarray((4,2,2))\n",
    "for i in range(4):\n",
    "    A = np.random.uniform(low=-1,high=1,size=(2,2))\n",
    "    B = np.matmul(A,A.T)\n",
    "    covars1[i,:,:] = B\n",
    "\n",
    "# Build an HMM instance and set parameters\n",
    "model1 = hmm.GaussianHMM(n_components=4, covariance_type=\"full\")\n",
    "\n",
    "# Instead of fitting it from the data, we directly set the estimated\n",
    "# parameters, the means and covariance of the components\n",
    "model1.startprob_ = startprob1\n",
    "model1.transmat_ = transmat1\n",
    "model1.means_ = means1\n",
    "model1.covars_ = covars1\n",
    "\n",
    "\n",
    "## Model 2\n",
    "\n",
    "startprob2 = np.array([0.7, 0.2, 0.1])\n",
    "\n",
    "# The transition matrix, note that there are no transitions possible\n",
    "# between component 1 and 3\n",
    "transmat2 = np.array([[0.4, 0.5, 0.1],\n",
    "                      [0.0, 0.2, 0.8],\n",
    "                      [0.7, 0.3, 0.0]])\n",
    "\n",
    "# The means of each component\n",
    "means2 = np.array([[0.0, 10.0],\n",
    "                   [0.0, -1.0],\n",
    "                   [9.0, 9.0]])\n",
    "\n",
    "covars2 = np.ndarray((3,2,2))\n",
    "for i in range(3):\n",
    "    A = np.random.uniform(low=-0.5,high=0.5,size=(2,2))\n",
    "    B = np.matmul(A,A.T)\n",
    "    covars2[i,:,:] = B\n",
    "\n",
    "# Build an HMM instance and set parameters\n",
    "model2 = hmm.GaussianHMM(n_components=3, covariance_type=\"full\")\n",
    "\n",
    "# Instead of fitting it from the data, we directly set the estimated\n",
    "# parameters, the means and covariance of the components\n",
    "model2.startprob_ = startprob2\n",
    "model2.transmat_ = transmat2\n",
    "model2.means_ = means2\n",
    "model2.covars_ = covars2\n",
    "\n",
    "## Model 3\n",
    "\n",
    "## TODO: Add an additional model with 4 states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: \n",
    "\n",
    "What are covars and means?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate samples of one single sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, Z1 = model1.sample(500)\n",
    "X2, Z2 = model2.sample(500)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# Plot the sampled data\n",
    "plt.plot(X1[:, 0], X1[:, 1], \".-\", label=\"model 1\", ms=6,\n",
    "         mfc=\"orange\", alpha=0.7)\n",
    "\n",
    "plt.plot(X2[:, 0], X2[:, 1], \".-\", label=\"model 2\", ms=6,\n",
    "         mfc=\"blue\", alpha=0.7)\n",
    "\n",
    "\n",
    "# Indicate the component numbers\n",
    "for i, m in enumerate(means1):\n",
    "    plt.text(m[0], m[1], 'C %i' % (i + 1),\n",
    "             size=17, horizontalalignment='center',\n",
    "             bbox=dict(alpha=.7, facecolor='cyan'))\n",
    "    \n",
    "for i, m in enumerate(means2):\n",
    "    plt.text(m[0], m[1], 'C %i' % (i + 1),\n",
    "             size=17, horizontalalignment='center',\n",
    "             bbox=dict(alpha=.7, facecolor='orange'))\n",
    "    \n",
    "    \n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Let's solve the first problem.\n",
    "\n",
    "Given the models and the two sequences of observations X1 and X2 generated above, estimate the log probabilies for each sequence on each model.\n",
    "\n",
    "What do the resulting numbers mean?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do it yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "* Predict for a given sequence and a given (corresponding) model, which is the most probable sequence of states\n",
    "* How can you meassure the successful \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do it yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Given the two available sequences, train some other models and compare how accurate both models are, assuming you know beforehand the correct number of states.\n",
    "\n",
    "Which state of the original models correspond to which state of the trained models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do it yourself!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
